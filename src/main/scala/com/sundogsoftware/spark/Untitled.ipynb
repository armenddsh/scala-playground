{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "873ca6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd1.sc:1: object apache is not a member of package org\n",
      "import org.apache.log4j._\n",
      "           ^\n",
      "cmd1.sc:3: object apache is not a member of package org\n",
      "import org.apache.spark.sql.functions._\n",
      "           ^\n",
      "cmd1.sc:13: object apache is not a member of package org\n",
      "import org.apache.hadoop.fs.Path\n",
      "           ^\n",
      "cmd1.sc:12: object apache is not a member of package org\n",
      "import org.apache.hadoop.fs.FileSystem\n",
      "           ^\n",
      "cmd1.sc:11: object apache is not a member of package org\n",
      "import org.apache.hadoop.conf.Configuration\n",
      "           ^\n",
      "cmd1.sc:9: object apache is not a member of package org\n",
      "import org.apache.spark.sql.SaveMode\n",
      "           ^\n",
      "cmd1.sc:8: object apache is not a member of package org\n",
      "import org.apache.spark.sql.SparkSession\n",
      "           ^\n",
      "cmd1.sc:7: object apache is not a member of package org\n",
      "import org.apache.spark.SparkConf\n",
      "           ^\n",
      "cmd1.sc:5: object apache is not a member of package org\n",
      "import org.apache.spark.storage.StorageLevel\n",
      "           ^\n",
      "cmd1.sc:4: object apache is not a member of package org\n",
      "import org.apache.spark.sql.{SparkSession, functions => F}\n",
      "           ^\n",
      "cmd1.sc:2: object apache is not a member of package org\n",
      "import org.apache.spark.sql.expressions.Window\n",
      "           ^\n",
      "cmd1.sc:16: not found: type SparkConf\n",
      "val conf = new SparkConf().setAppName(\"Example App\")\n",
      "               ^\n",
      "cmd1.sc:17: not found: type SparkSession\n",
      "val spark: SparkSession = SparkSession.builder.config(conf).getOrCreate()\n",
      "           ^\n",
      "cmd1.sc:17: not found: value SparkSession\n",
      "val spark: SparkSession = SparkSession.builder.config(conf).getOrCreate()\n",
      "                          ^\n",
      "Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "Compilation Failed",
     "output_type": "error"
    }
   ],
   "source": [
    "import org.apache.log4j._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{SparkSession, functions => F}\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.SaveMode\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.fs.FileSystem\n",
    "import org.apache.hadoop.fs.Path\n",
    "\n",
    "println(\"Initializing Spark context...\")\n",
    "val conf = new SparkConf().setAppName(\"Example App\")\n",
    "val spark: SparkSession = SparkSession.builder.config(conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "25f7a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd1.sc:10: not found: value Logger\n",
      "    Logger.getLogger(\"org\").setLevel(Leavel.ERROR)\n",
      "    ^\n",
      "cmd1.sc:10: not found: value Leavel\n",
      "    Logger.getLogger(\"org\").setLevel(Leavel.ERROR)\n",
      "                                     ^\n",
      "cmd1.sc:11: not found: value Logger\n",
      "    val logger = Logger.getLogger(this.getClass)\n",
      "                 ^\n",
      "cmd1.sc:15: not found: value SparkSession\n",
      "    val spark = SparkSession.builder()\n",
      "                ^\n",
      "Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "Compilation Failed",
     "output_type": "error"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
